{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/My Drive/R/Tempel-HSC-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import models, train_model\n",
    "from src.scripts.create_dataset import create_dataset\n",
    "from src.utils import utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # Exlude _train/_test and file ending\n",
    "    'data_set': '',\n",
    "\n",
    "    # 'svm', lstm', 'gru', 'attention' (only temporal) or 'da-rnn' (input and temporal attention)\n",
    "    'model': 'attention',\n",
    "\n",
    "    # Number of hidden units in the encoder\n",
    "    'hidden_size': 128,\n",
    "\n",
    "    # Droprate (applied at input)\n",
    "    'dropout_p': 0.5,\n",
    "\n",
    "    # Note, no learning rate decay implemented\n",
    "    'learning_rate': 0.001,\n",
    "\n",
    "    # Size of mini batch\n",
    "    'batch_size': 256,\n",
    "\n",
    "    # Number of training iterations\n",
    "    'num_of_epochs': 50\n",
    "}\n",
    "\n",
    "dataset_features = {\n",
    "    'dataset': 'H3N2',\n",
    "\n",
    "    'num_of_runs': 5,\n",
    "\n",
    "    'start_year': 2001,\n",
    "\n",
    "    'end_year': 2016,\n",
    "\n",
    "    'method': 'dbscan'\n",
    "}\n",
    "\n",
    "create_dataset_cmd = True\n",
    "train_cmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_dataset_cmd:\n",
    "    for i in range(dataset_features['num_of_runs']):\n",
    "        create_dataset(dataset_features['start_year'], dataset_features['end_year'], dataset_features['dataset'],\n",
    "                       i + 1, method=dataset_features['cluster'])\n",
    "if create_dataset_cmd:\n",
    "    res_path = './results/Tempel/{}_T{}_{}'.format(dataset_features['dataset'],\n",
    "                                            dataset_features['end_year'] -\n",
    "                                            dataset_features['start_year'],\n",
    "                                            dataset_features['end_year'])\n",
    "\n",
    "    if not os.path.exists(res_path):\n",
    "        os.mkdir(res_path)\n",
    "    final_res = {}\n",
    "    for i in range(5):\n",
    "        parameters['data_set'] = './data/processed/{}_T{}_{}/{}/triplet_cluster'.format(dataset_features['dataset'],\n",
    "                                                                                        dataset_features['end_year'] -\n",
    "                                                                                        dataset_features['start_year'],\n",
    "                                                                                        dataset_features['end_year'],\n",
    "                                                                                        i + 1)\n",
    "        torch.manual_seed(1)\n",
    "        np.random.seed(1)\n",
    "\n",
    "        train_trigram_vecs, train_labels = utils.read_dataset(dataset_features['dataset'],\n",
    "                                                              parameters['data_set'] + '_train.csv', concat=False)\n",
    "        test_trigram_vecs, test_labels = utils.read_dataset(dataset_features['dataset'],\n",
    "                                                            parameters['data_set'] + '_test.csv', concat=False)\n",
    "\n",
    "        X_train = torch.tensor(train_trigram_vecs, dtype=torch.float32)\n",
    "        Y_train = torch.tensor(train_labels, dtype=torch.int64)\n",
    "        X_test = torch.tensor(test_trigram_vecs, dtype=torch.float32)\n",
    "        Y_test = torch.tensor(test_labels, dtype=torch.int64)\n",
    "\n",
    "        input_dim = X_train.shape[2]\n",
    "        seq_length = X_train.shape[0]\n",
    "        output_dim = 2\n",
    "\n",
    "        net = models.AttentionModel(seq_length, input_dim, output_dim, parameters['hidden_size'],\n",
    "                                    parameters['dropout_p'])\n",
    "\n",
    "        result, (fpr_rnn, tpr_rnn) = train_model.train_rnn(net, False, parameters['num_of_epochs'], parameters['learning_rate'],\n",
    "                                       parameters['batch_size'], X_train, Y_train, X_test, Y_test, False)\n",
    "        print('Finished')\n",
    "        df = pd.DataFrame.from_dict(result)\n",
    "        df.to_csv(res_path + '/{}.csv'.format(i))\n",
    "        for k, v in result.items():\n",
    "            if k not in final_res:\n",
    "                final_res[k] = [0]\n",
    "            final_res[k][0] += v[0] / 5\n",
    "\n",
    "    df = pd.DataFrame.from_dict(final_res)\n",
    "    df.to_csv(res_path + '/final.csv')\n",
    "\n",
    "    np.save(res_path + '/fpr', fpr_rnn)\n",
    "    np.save(res_path + '/tpr', tpr_rnn)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}